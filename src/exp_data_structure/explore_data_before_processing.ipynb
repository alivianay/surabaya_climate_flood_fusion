{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44378c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script_0_exploration.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96375b93",
   "metadata": {},
   "source": [
    "### Normalize Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16cc0eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\Kuliah\\Semester 7\\Data Wrangling\\UTS\\surabaya_climate_flood_fusion\\src\\exp_data_structure\n",
      "Attempting to rename files in: ..\\..\\data\\data_iklim_2023\n",
      "\n",
      "\n",
      "File renaming complete!\n"
     ]
    }
   ],
   "source": [
    "def simplify_filename(data_folder):\n",
    "    all_files = glob.glob(os.path.join(data_folder, \"*\"))\n",
    "    \n",
    "    if not all_files:\n",
    "        return\n",
    "    \n",
    "    renamed_count = 0\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "            \n",
    "        original_name = os.path.basename(file_path)\n",
    "        directory = os.path.dirname(file_path)\n",
    "        file_ext = os.path.splitext(original_name)[1]\n",
    "        name_without_ext = os.path.splitext(original_name)[0]\n",
    "\n",
    "        normalized_name = name_without_ext.lower()\n",
    "        normalized_name = normalized_name.replace(' ', '_')\n",
    "        normalized_name = normalized_name.replace('-', '_')\n",
    "   \n",
    "        while '__' in normalized_name:\n",
    "            normalized_name = normalized_name.replace('__', '_')\n",
    "\n",
    "        normalized_name = normalized_name.strip('_')\n",
    "\n",
    "        normalized_name += file_ext.lower()\n",
    "\n",
    "        new_file_path = os.path.join(directory, normalized_name)\n",
    "\n",
    "        if original_name == normalized_name:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(new_file_path):\n",
    "                error_count += 1\n",
    "                continue\n",
    "                \n",
    "            os.rename(file_path, new_file_path)\n",
    "            renamed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Update path to go up 2 levels from src/exp_data_structure\n",
    "    data_folder = r'..\\..\\data\\data_iklim_2023'\n",
    "    \n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Attempting to rename files in: {data_folder}\\n\")\n",
    "    \n",
    "    simplify_filename(data_folder)\n",
    "    print(\"\\nFile renaming complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d184f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"..\\..\\data\\data_iklim_2023\"\n",
    "output_path = r\"..\\..\\data\\normalize\"\n",
    "\n",
    "\n",
    "files = glob.glob(os.path.join(folder_path, \"*tanjung*.xlsx\"))\n",
    "\n",
    "if not files:\n",
    "    raise SystemExit\n",
    "\n",
    "for f in files:\n",
    "    df_raw = pd.read_excel(f, header=None)\n",
    "\n",
    "    header_row = df_raw[df_raw.eq(\"TANGGAL\").any(axis=1)].index[0]\n",
    "\n",
    "    df = pd.read_excel(f, header=header_row)\n",
    "\n",
    "    df = df.drop(range(0, header_row + 1))\n",
    "\n",
    "    ket_row = df[df.eq(\"KETERANGAN:\").any(axis=1)].index\n",
    "\n",
    "    if len(ket_row) > 0:\n",
    "        stop_at = ket_row[0]\n",
    "        df = df.loc[:stop_at - 1] \n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    out_name = os.path.splitext(os.path.basename(f))[0] + \"_clean.csv\"\n",
    "    df.to_csv(os.path.join(output_path, out_name), index=False)\n",
    "\n",
    "print(\"File cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661ebad",
   "metadata": {},
   "source": [
    "### Normalize X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff536f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TANGGAL</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>tweet1</td>\n",
       "      <td>hujan deres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>tweet4</td>\n",
       "      <td>dengerin suara hujan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>tweet2</td>\n",
       "      <td>hujan petir suara pesawat deket sekali admin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>tweet5</td>\n",
       "      <td>hati hati ya pulangnya sedia jas hujan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>tweet3</td>\n",
       "      <td>surabaya hujan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TANGGAL tweet_id                                    tweet_text\n",
       "17   2023-01-18   tweet1                                   hujan deres\n",
       "1112 2023-01-18   tweet4                         dengerin suara hujan \n",
       "382  2023-01-18   tweet2  hujan petir suara pesawat deket sekali admin\n",
       "1477 2023-01-18   tweet5        hati hati ya pulangnya sedia jas hujan\n",
       "747  2023-01-18   tweet3                                surabaya hujan"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load file\n",
    "df = pd.read_excel(\"../../data/data_iklim_2023/data_sraping_x_2023.xlsx\")\n",
    "\n",
    "\n",
    "# melt all tweet columns\n",
    "tweet_cols = [col for col in df.columns if col.startswith(\"tweet\")]\n",
    "\n",
    "df_long = df.melt(a\n",
    "    id_vars=\"TANGGAL\",\n",
    "    value_vars=tweet_cols,\n",
    "    var_name=\"tweet_id\",\n",
    "    value_name=\"tweet_text\"\n",
    ")\n",
    "\n",
    "# drop empty rows\n",
    "df_long = df_long.dropna(subset=[\"tweet_text\"])\n",
    "df_long = df_long[df_long[\"tweet_text\"].str.strip() != \"\"]\n",
    "\n",
    "# sort by date\n",
    "df_long = df_long.sort_values([\"TANGGAL\"])\n",
    "\n",
    "# save to csv\n",
    "df_long.to_csv(r\"../../data/normalize/tweets_normalized.csv\", index=False)\n",
    "\n",
    "df_long.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f108faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: d:\\Kuliah\\Semester 7\\Data Wrangling\\UTS\\surabaya_climate_flood_fusion\\src\\exp_data_structure\n",
      "List root: ['explore_data_before_processing.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"List root:\", os.listdir(os.getcwd()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba644c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: d:\\Kuliah\\Semester 7\\Data Wrangling\\UTS\\surabaya_climate_flood_fusion\\src\\exp_data_structure\n",
      "List parent: ['data_normalize', 'exp_data_structure', 'processing']\n",
      "List grandparent: ['.git', '.gitignore', '.python-version', '.venv', 'data', 'main.py', 'pyproject.toml', 'README.md', 'src', 'uv.lock']\n"
     ]
    }
   ],
   "source": [
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"List parent:\", os.listdir(\"../\"))\n",
    "print(\"List grandparent:\", os.listdir(\"../../\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cc347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing data/data_iklim_2023:\n",
      "['data_sraping_x_2023.xlsx', 'tanjung_perak_1_agustus_2023.xlsx', 'tanjung_perak_1_april_2023.xlsx', 'tanjung_perak_1_desember_2023.xlsx', 'tanjung_perak_1_februari_2023.xlsx', 'tanjung_perak_1_januari_2023.xlsx', 'tanjung_perak_1_juli_2023.xlsx', 'tanjung_perak_1_juni_2023.xlsx', 'tanjung_perak_1_maret_2023.xlsx', 'tanjung_perak_1_mei_2023.xlsx', 'tanjung_perak_1_november_2023.xlsx', 'tanjung_perak_1_oktober_2023.xlsx', 'tanjung_perak_1_september_2023.xlsx']\n"
     ]
    }
   ],
   "source": [
    "print(\"Listing data/data_iklim_2023:\")\n",
    "print(os.listdir(\"../../data/data_iklim_2023\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f1cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
